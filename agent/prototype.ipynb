{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AniMate Ver. 1.0.0\n",
    "\n",
    "This notebook is used to prototype the LLM Agent that will act as the brain of the LLM-based Chatbot. Here I:\n",
    "1. Define the tools available to the agent\n",
    "2. Experiment with different prompt templates when constructing the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Construction\n",
    "\n",
    "The API that the agent will use to find up to date anime related information is the [Jikan API](https://jikan.moe/). It parses the website MyAnimeList.net (MAL), one of the largest anime databases available, to satisfy the needs of the API.\n",
    "\n",
    "The capabilities I need to provide the agent for core functionality are listed below:\n",
    "- **Retrieve anime synopsis:** Get the anime's synopsis. *Wikipedia*\n",
    "- **Retrieve anime ID:** Get the MAL ID of the anime. Scraped from the MAL site\n",
    "- **Retrieve real-time statistics:** Get the live statistics on an anime. *Jikan API endpoint: getAnimeStatistics*\n",
    "- **Retrieve recommendations:** Get other anime recommendations based on a given anime. *Jikan API endpoint: getAnimeRecommendations*\n",
    "- **Retrieve sentiment:** Get sentiment around the anime. *Jikan API endpoint: getAnimeReviews*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.352)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (0.1.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (0.0.75)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (2.26.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (2.0.24)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (0.0.6)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (1.21.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain) (4.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langchain) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: Levenshtein==0.23.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-Levenshtein) (0.23.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Levenshtein==0.23.0->python-Levenshtein) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.6.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>4->openai) (0.4.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tiktoken) (2.26.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: wikipedia in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wikipedia) (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\halor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install fuzzywuzzy\n",
    "%pip install langchain\n",
    "%pip install python-Levenshtein\n",
    "%pip install openai\n",
    "%pip install tiktoken\n",
    "%pip install wikipedia\n",
    "\n",
    "%pip install python-dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, yaml, urllib.parse\n",
    "from enum import Enum\n",
    "from typing import Type, Optional\n",
    "from fuzzywuzzy import fuzz\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.agents.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, Tool, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.tools import ToolException\n",
    "from langchain.requests import RequestsWrapper\n",
    "from langchain.prompts import PromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Anime Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Frieren\\nSummary: Frieren: Beyond Journey\\'s End (Japanese: 葬送のフリーレン, Hepburn: Sōsō no Furīren, pp. \"Frieren, the Final Farewell to the Dead\") is a Japanese manga series written by Kanehito Yamada and illustrated by Tsukasa Abe. It has been serialized in Shogakukan\\'s shōnen manga magazine Weekly Shōnen Sunday since April 2020, with its chapters collected in twelve tankōbon volumes as of December 2023. The series is licensed for English release in North America by Viz Media. An anime television series adaptation produced by Madhouse premiered in September 2023.\\nBy December 2023, the manga had over 17 million copies in circulation. In 2021, Frieren: Beyond Journey\\'s End won the 14th Manga Taishō and the New Creator Prize of the 25th annual Tezuka Osamu Cultural Prize.\\n\\nPage: Frieren (character)\\nSummary: Frieren (Japanese: フリーレン, Hepburn: Furīren) is the title character and protagonist of the Japanese manga series Frieren: Beyond Journey\\'s End, written by Kanehito Yamada and illustrated by Tsukasa Abe. Frieren is a former member of the party of adventurers who defeated the Demon King and restored harmony to the world after a ten-year quest. Frieren returns to the capital fifty years later; however, humanity has changed, and her former companions have distinctly aged. After one last adventure to see the meteor shower, Himmel dies of old age. During the funeral, Frieren expressed guilt for not attempting to learn more about him. Frieren then pays a visit to her other former comrades. She accepts an offer to teach and care for Fern, an orphaned child adopted by Heiter. She also receives an invitation to travel far north, to the resting place of souls, and see Himmel again to bid the hero a fitting farewell and express her feelings. To fulfill those requests, Frieren embarks on a journey together with Fern while still pursuing her passion for learning magic.\\nWhile initially conceptualized as a comical fighter, Yamada scrapped multiple ideas she had for Frieren until deciding to make her an elf who grows in the story while remembering Himmel. In the anime adaptation, she is voiced by Atsumi Tanezaki in Japanese and Mallorie Rodak in English. Critical response to Frieren\\'s character was mostly positive due to how the series focuses on Frieren\\'s view of life and how she aims to become a better person. The further exploration of her dark past was also praised for how it changed people\\'s views of her.\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "wiki_tool = Tool.from_function(\n",
    "        func=wikipedia.run,\n",
    "        name=\"wikipedia_lookup\",\n",
    "        description=\"get anime synopsis\",\n",
    "        handle_tool_error=True\n",
    "    )\n",
    "\n",
    "wikipedia.run(\"Sousou no Frieren\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool]\n",
    "key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0, openai_api_key=key)\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True\n",
    ")\n",
    "result = agent_executor({\"input\": \"Tell me the plot of Jujutsu Kaisen\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Anime ID\n",
    "\n",
    "The agent needs the ability to retrieve the MyAnimeList (MAL) ID of a given anime as this ID must be included in the request for almost every endpoint of the Jikan API. Retrieving the MAL ID of a given anime is trivial as this information can simply be scraped from the internet, so the tool for this will simply enable the LLM to scrape the appropriate page of the site for the id using the name of the anime e.g. *getId(anime_name: string) -> int*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Naruto: Shippuuden', 1735)\n"
     ]
    }
   ],
   "source": [
    "def search_anime_name(animeName: str) -> dict[str, any]:\n",
    "    url = 'https://api.jikan.moe/v4/anime?q={name}'.format(name=animeName)\n",
    "    response = requests.get(url)\n",
    "    response_json = response.json()\n",
    "    return response_json['data']\n",
    "\n",
    "def get_best_match(query: str, search_results: list[dict[str, any]]) -> tuple[str, str]:\n",
    "    # Sort by levenshtein distance (edit distance) between query and title. The closest\n",
    "    # match will be the final result\n",
    "    search_results_sorted = sorted(search_results, key=lambda sr: fuzz.ratio(query, sr['title']))\n",
    "    best_match = search_results_sorted[len(search_results) - 1]\n",
    "    best_match_title = best_match['title']\n",
    "    best_match_id = best_match['mal_id'] \n",
    "    return best_match_title, best_match_id\n",
    "\n",
    "# Test\n",
    "query = \"Naruto Shippuden\"\n",
    "search_results = search_anime_name(query)\n",
    "best_match = get_best_match(query, search_results)\n",
    "print(best_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeIDLookupSchema(BaseModel):\n",
    "    query: str = Field(description=\"anime name\")\n",
    "\n",
    "\n",
    "class AnimeIDLookupTool(BaseTool):\n",
    "    name = \"anime_id_lookup\"\n",
    "    description = \"Useful for when you need to retrieve the id of an anime\"\n",
    "    args_schema: Type[AnimeIDLookupSchema] = AnimeIDLookupSchema\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        try:    \n",
    "            searchResults = search_anime_name(query)\n",
    "            if searchResults:\n",
    "                _, bestMatchId = get_best_match(query, searchResults)\n",
    "                return bestMatchId\n",
    "            raise ToolException(\"Anime not found\")\n",
    "        except Exception as e:\n",
    "            raise ToolException(e)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"anime_id_lookup does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "Experimentation is carried out using OpenAI function calling, however useful resources for creating agents and learning how to use Llama 2 as an agent locally are listed below: \n",
    "- https://www.pinecone.io/learn/llama-2/\n",
    "- https://philschmid.github.io/easyllm/examples/llama2-agent-example/#basic-example-of-using-a-tool-with-llama-2-70b\n",
    "- https://medium.com/@gil.fernandes/langchain-chat-with-custom-tools-functions-and-memory-e34daa331aa7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0, openai_api_key=key)\n",
    "\n",
    "anime_id_lookup_tool = AnimeIDLookupTool()\n",
    "anime_id_lookup_tool.handle_tool_error = True\n",
    "\n",
    "tools = [anime_id_lookup_tool]\n",
    "agent_executor = initialize_agent(\n",
    "    tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True\n",
    ")\n",
    "result = agent_executor({\"input\": \"Tell me the anime ID of Cowboy Bepop\"}) # LLM should return 1\n",
    "result = agent_executor({\"input\": \"Tell me the anime ID of ...\"}) # LLM should throw error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining functionality\n",
    "\n",
    "The other aspects of the agent's functionality are non-trivial in that they all require allowing the agent to make API calls to the Jikan API. Langchain supports three main ways of doing this:\n",
    "1. **OpenAPI** - If the API follows the OpenAPI spec, we can use the OpenAPI toolkit to parse the APIs OpenAPI specification and provide the LLM with the available tools directly. Refer to: https://python.langchain.com/docs/use_cases/apis and https://python.langchain.com/docs/integrations/toolkits/openapi\n",
    "2. **Non-OpenAPI** - If the API doesn't follow the OpenAPI spec, we can define our own documentation for the API to construct the chain. As far as I know there is no standardised way of doing this, so it would require examining the examples in the Langchain docs and going through trial and error. Refer to: https://python.langchain.com/docs/use_cases/apis\n",
    "3. **Custom Tools** - We define a custom tool for each endpoint required, and under the hood facilitate fetching the APIs response\n",
    "\n",
    "Thankfully the JikanAPI provides an OpenAPI spec, so approaches 1 & 3 are viable. I will carry out experimentation below and decide which will be optimal for the final chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5280/4253747761.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"jikan_openapi.yaml\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mraw_jikan_api_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mjikan_api_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_openapi_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_jikan_api_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(stream, Loader)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_single_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\constructor.py\u001b[0m in \u001b[0;36mget_single_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_single_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Ensure that the stream contains a single document and construct it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_single_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_document\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mget_single_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mdocument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStreamEndEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mdocument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_document\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# Ensure that the stream contains no more documents.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_document\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# Compose the root node.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Drop the DOCUMENT-END event.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mitem_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[1;31m#node.value[item_key] = item_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mitem_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[1;31m#node.value[item_key] = item_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mitem_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[1;31m#node.value[item_key] = item_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascend_resolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;31m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m#            \"found duplicate key\", key_event.start_mark)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mitem_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[1;31m#node.value[item_key] = item_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_scalar_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequenceStartEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_sequence_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMappingStartEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_mapping_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\composer.py\u001b[0m in \u001b[0;36mcompose_sequence_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manchor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequenceEndEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\parser.py\u001b[0m in \u001b[0;36mcheck_event\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_event\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchoices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\parser.py\u001b[0m in \u001b[0;36mparse_flow_sequence_first_entry\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_mark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_flow_sequence_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_flow_sequence_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\parser.py\u001b[0m in \u001b[0;36mparse_flow_sequence_entry\u001b[1;34m(self, first)\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlowSequenceEndToken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_flow_sequence_entry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_flow_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0mevent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequenceEndEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_mark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_mark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\parser.py\u001b[0m in \u001b[0;36mparse_flow_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_flow_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_block_node_or_indentless_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\parser.py\u001b[0m in \u001b[0;36mparse_node\u001b[1;34m(self, block, indentless_sequence)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             start_mark, end_mark, flow_style=True)\n\u001b[0;32m    341\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_flow_sequence_first_entry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlowMappingStartToken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m                     \u001b[0mend_mark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeek_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_mark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                     event = MappingStartEvent(anchor, tag, implicit,\n",
      "\u001b[1;32mc:\\Users\\halor\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\scanner.py\u001b[0m in \u001b[0;36mcheck_token\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Check if the next token is one of the given types.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneed_more_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_more_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0, openai_api_key=key)\n",
    "requests_wrapper = RequestsWrapper()\n",
    "\n",
    "# from urllib.request import urlretrieve\n",
    "# urlretrieve(\"https://raw.githubusercontent.com/jikan-me/jikan-rest/master/storage/api-docs/api-docs.json\",\"jikan_openapi.yaml\")\n",
    "\n",
    "with open(\"jikan_openapi.yaml\", encoding=\"utf-8\") as f:\n",
    "    raw_jikan_api_spec = yaml.load(f, Loader=yaml.Loader)\n",
    "jikan_api_spec = reduce_openapi_spec(raw_jikan_api_spec)\n",
    "\n",
    "jikan_agent = planner.create_openapi_agent(jikan_api_spec, requests_wrapper, llm)\n",
    "\n",
    "# Using simple OpenAPI agent\n",
    "# NOTE: This agent does not have access to the id lookup tool, so the id must be included in the prompt\n",
    "\n",
    "user_query = (\n",
    "    \"Tell me the plot of the anime Cowboy Bepop. It has an id of 1\"\n",
    ")\n",
    "jikan_agent.run(user_query)\n",
    "\n",
    "# OpenAPI agent + ID lookup tool\n",
    "# Here the OpenAPI agent is used as a tool alongside the id lookup tool. Notice that the prompt no\n",
    "# longer needs to include the anime ID. Instead, the main LLM is used as an orchestrator, and is instructed\n",
    "# to pass the id retrieved using the id lookup tool to the OpenAPI agent.\n",
    "\n",
    "jikan_tool = Tool.from_function(\n",
    "        func=jikan_agent.run,\n",
    "        name=\"anime_api_agent\",\n",
    "        description=\"useful for when you need to answer anime related queries. The input to this tool should be in the form '[query] anime id: [id]'\",\n",
    "        handle_tool_error=True\n",
    "    )\n",
    "\n",
    "anime_id_lookup_tool = AnimeIDLookupTool()\n",
    "anime_id_lookup_tool.handle_tool_error = True\n",
    "\n",
    "tools = [anime_id_lookup_tool, jikan_tool]\n",
    "agent_executor = initialize_agent(\n",
    "    tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True\n",
    ")\n",
    "\n",
    "result = agent_executor({\"input\": \"Tell me the plot of the anime Cowboy Bepop\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86330\n"
     ]
    }
   ],
   "source": [
    "# class JikanEndpoints(Enum):\n",
    "#     GENERAL_INFO = \"https://api.jikan.moe/v4/anime/{id}\"\n",
    "#     EPISODE_INFO = \"https://api.jikan.moe/v4/anime/{id}/episodes\"\n",
    "#     CHARACTER_INFO = \"https://api.jikan.moe/v4/anime/{id}/characters\"\n",
    "\n",
    "# class JikanResponseKeys(Enum):\n",
    "#     TITLE = \"TITLE\"\n",
    "#     URL = \"URL\"\n",
    "#     TYPE = \"TYPE\"\n",
    "#     STATUS = \"STATUS\"\n",
    "#     NUM_EPISODES = \"NUM_EPISODES\"\n",
    "#     EPISODES = \"EPISODES\"\n",
    "#     CHARACTERS = \"CHARACTERS\"\n",
    "#     AIRING = \"AIRING\"\n",
    "#     AIRED = \"AIRED\"\n",
    "#     DURATION = \"DURATION\"\n",
    "#     RATING = \"RATING\"\n",
    "#     SCORE = \"SCORE\"\n",
    "#     SCORED_BY = \"SCORED BY\"\n",
    "#     RANK = \"RANK\"\n",
    "#     SYNOPSIS = \"SYNOPSIS\"\n",
    "#     BACKGROUND = \"BACKGROUND\"\n",
    "#     LICENSORS = \"LICENSORS\"\n",
    "#     ANIMATION_STUDIOS = \"ANIMATION STUDIOS [NOT A PRODUCER]\"\n",
    "#     PRODUCERS = \"PRODUCERS\"\n",
    "#     GENRES = \"GENRES\"\n",
    "\n",
    "# def jikan_get_request(endpoint: JikanEndpoints, animeId: int) -> dict[str, any]:\n",
    "#     url = endpoint.value.format(id=animeId)\n",
    "#     response = requests.get(url)\n",
    "#     response_json = response.json()\n",
    "#     data = response_json['data']\n",
    "#     return data\n",
    "\n",
    "# def construct_dict(keys: list[str], values: list[str]) -> dict[str, str]:\n",
    "#     new_dict = dict(zip(keys, values))\n",
    "#     return new_dict\n",
    "\n",
    "# def parse_names(objList: list[dict[str, any]]) -> str:\n",
    "#     namesList = list(map(lambda x: x['name'], objList))\n",
    "#     names = \", \".join(namesList)\n",
    "#     return names\n",
    "\n",
    "# def parse_aired_dates(aired: dict[str, any]) -> str:\n",
    "#     aired_string = 'from {start} to {end}' \\\n",
    "#                     .format(start=aired['from'], end=aired['to'])\n",
    "#     return aired_string\n",
    "\n",
    "# def parse_voice_actors(actors: list[dict[str, any]]) -> str:\n",
    "#     va_info = list(map(lambda a: \"Actor Name: {name}, Actor Language: {language}\".format(name=a['person']['name'], language=a['language']), actors))\n",
    "#     return va_info\n",
    "    \n",
    "# def parse_characters(characters: list[dict[str, any]]) -> str:\n",
    "#     char_info = list(map(lambda c: \"Name: {name}, Role: {role}, Voice Actors: {actors}\" \\\n",
    "#                     .format(name=c['character']['name'], role=c['role'], actors=parse_voice_actors(c['voice_actors'])), characters))\n",
    "#     return char_info\n",
    "\n",
    "# def get_general_info(animeId: int) -> str:\n",
    "#     endpoint = JikanEndpoints.GENERAL_INFO\n",
    "#     data = jikan_get_request(endpoint, animeId)\n",
    "    \n",
    "#     keys = [\n",
    "#         JikanResponseKeys.TITLE.value, \n",
    "#         JikanResponseKeys.URL.value, \n",
    "#         JikanResponseKeys.TYPE.value, \n",
    "#         JikanResponseKeys.STATUS.value,\n",
    "#         JikanResponseKeys.NUM_EPISODES.value, \n",
    "#         JikanResponseKeys.AIRED.value, \n",
    "#         JikanResponseKeys.AIRING.value,\n",
    "#         JikanResponseKeys.DURATION.value, \n",
    "#         JikanResponseKeys.RATING.value, \n",
    "#         JikanResponseKeys.SCORE.value, \n",
    "#         JikanResponseKeys.SCORED_BY.value,\n",
    "#         JikanResponseKeys.RANK.value, \n",
    "#         JikanResponseKeys.SYNOPSIS.value, \n",
    "#         JikanResponseKeys.BACKGROUND.value, \n",
    "#         JikanResponseKeys.LICENSORS.value,\n",
    "#         JikanResponseKeys.ANIMATION_STUDIOS.value, \n",
    "#         JikanResponseKeys.PRODUCERS.value, \n",
    "#         JikanResponseKeys.GENRES.value\n",
    "#         ]\n",
    "#     values = [\n",
    "#         data['title'], \n",
    "#         data['url'], \n",
    "#         data['type'], \n",
    "#         data['status'], \n",
    "#         data['episodes'],\n",
    "#         data['airing'],\n",
    "#         parse_aired_dates(data['aired']),\n",
    "#         data['duration'],\n",
    "#         data['rating'],\n",
    "#         data['score'],\n",
    "#         data['scored_by'],\n",
    "#         data['rank'],\n",
    "#         data['synopsis'],\n",
    "#         data['background'],\n",
    "#         parse_names(data['licensors']),\n",
    "#         parse_names(data['studios']),\n",
    "#         parse_names(data['producers']),\n",
    "#         parse_names(data['genres'])\n",
    "#         ]\n",
    "    \n",
    "#     data_parsed = construct_dict(keys, values)\n",
    "#     data_as_string = str(data_parsed)\n",
    "#     return data_as_string\n",
    "\n",
    "# def get_character_info(animeId: int) -> str:\n",
    "#     url = JikanEndpoints.CHARACTER_INFO\n",
    "#     data = jikan_get_request(url, animeId)\n",
    "    \n",
    "#     keys = [\n",
    "#         JikanResponseKeys.CHARACTERS.value\n",
    "#         ]\n",
    "#     values = [\n",
    "#         parse_characters(data)\n",
    "#         ]\n",
    "    \n",
    "#     data_parsed = construct_dict(keys, values)\n",
    "#     data_as_string = str(data_parsed)\n",
    "#     return data_as_string\n",
    "\n",
    "# def get_anime_info(animeId: int, option: str) -> str:\n",
    "#     if (option == \"general_info\"):\n",
    "#         return get_general_info(animeId)\n",
    "#     elif (option == \"character_info\"):\n",
    "#         return get_character_info(animeId)\n",
    "\n",
    "# option = \"character_info\"\n",
    "# print(len(get_anime_info(20, option)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWS: Review Summary: This review criticizes the series for its lack of interesting plot, excessive filler episodes, and unappealing characters, and advises against watching it due to the wasted time and lack of worth.\n",
      "Review Summary: The reviewer enjoyed Naruto and found the characters and supporting cast to be well-developed, but acknowledged pacing issues and the potential for frustration with certain arcs.\n",
      "Review Summary: The reviewer praises Naruto for its unique ninja aspect, character development, emotional depth, and exploration of themes such as friendship and bonds, while acknowledging that the series has changed over time and may not appeal to everyone.\n",
      "Review Summary: The reviewer finds Naruto to be a popular anime series that appeals to young teenagers, but they personally found it to be average and have seen better shows, although they appreciate the soundtrack.\n",
      "Review Summary: The reviewer finds Naruto to be overhyped and disappointing, with too many fights, bad fillers, immature silliness, average animation, and annoying characters, but acknowledges the popularity of the show and hopes that Shippuden will be better.\n",
      "Source: MyAnimeList.net\n"
     ]
    }
   ],
   "source": [
    "class JikanEndpoints(Enum):\n",
    "    STATISTICS = \"https://api.jikan.moe/v4/anime/{id}/statistics\"\n",
    "    RECOMMENDATIONS = \"https://api.jikan.moe/v4/anime/{id}/recommendations\"\n",
    "    REVIEWS = \"https://api.jikan.moe/v4/anime/{id}/reviews\"\n",
    "    \n",
    "def jikan_get_request(endpoint: JikanEndpoints, anime_id: int, params: Optional[dict[str, str]] = None) -> dict[str, any]:\n",
    "    url = endpoint.value.format(id=anime_id)\n",
    "    \n",
    "    if params:\n",
    "        params_formatted = urllib.parse.urlencode(params)\n",
    "        url_with_params = \"{url}?{params}\".format(url=url, params=params_formatted)\n",
    "        url = url_with_params\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response_json = response.json()\n",
    "    data = response_json['data']\n",
    "    return data\n",
    "\n",
    "def format_scores(scores: list[dict[str, any]]) -> str:\n",
    "    scores_formatted = list(map(lambda s: \"{}/10, Votes for score: {}, Percentage of total: {}\".format(s['score'], s['votes'], s['percentage']), scores))\n",
    "    scores_formatted = \"\\n\".join(scores_formatted)\n",
    "    return scores_formatted\n",
    "\n",
    "def format_recommendations(recommendations: list[dict[str, any]]) -> str:\n",
    "    recommendations_formatted = list(map(lambda s: \"{}\".format(s['entry']['title']), recommendations))\n",
    "    recommendations_formatted = \", \".join(recommendations_formatted)\n",
    "    return recommendations_formatted\n",
    "\n",
    "def filter_reviews(raw_reviews: list[dict[str, any]], top_k: int) -> str:\n",
    "    reviews_filtered = sorted(raw_reviews, key=lambda r: r['reactions']['overall'])\n",
    "    return reviews_filtered[len(reviews_filtered) - top_k:]\n",
    "\n",
    "def summarise_review(review: str) -> str:\n",
    "    key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0, openai_api_key=key)\n",
    "    template = \"\"\"Summarise this review in ONLY one sentence:\n",
    "    Review: {review}\"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    \n",
    "    result = llm_chain.run(review)\n",
    "    return result\n",
    "\n",
    "def format_reviews(reviews: list[dict[str, any]]) -> str:\n",
    "    reviews_formatted = list(map(lambda r: \"Review Summary: {}\".format(summarise_review(r['review'])), reviews))\n",
    "    reviews_formatted = \"\\n\".join(reviews_formatted)\n",
    "    return reviews_formatted\n",
    "    \n",
    "def get_anime_statistics(anime_id: int) -> str:\n",
    "    endpoint = JikanEndpoints.STATISTICS\n",
    "    data = jikan_get_request(endpoint, anime_id)\n",
    "\n",
    "    stats_formatter = \"SCORES: {}\\nSource: MyAnimeList.net\"\n",
    "    scores_as_string = format_scores(data['scores'])\n",
    "    data_parsed = stats_formatter.format(scores_as_string)\n",
    "    return data_parsed\n",
    "\n",
    "def get_anime_recommendations(anime_id: int, num_recommendations: int = 5) -> str:\n",
    "    endpoint = JikanEndpoints.RECOMMENDATIONS\n",
    "    data = jikan_get_request(endpoint, anime_id)\n",
    "    data_filtered = data[:num_recommendations]\n",
    "    \n",
    "    recommendations_formatter = \"RECOMMENDATIONS: {}\\nSource: MyAnimeList.net\"\n",
    "    recommendations_as_string = format_recommendations(data_filtered)\n",
    "    data_parsed = recommendations_formatter.format(recommendations_as_string)\n",
    "    return data_parsed\n",
    "\n",
    "def get_anime_reviews(anime_id: int, top_k: int = 5) -> str:\n",
    "    endpoint = JikanEndpoints.REVIEWS\n",
    "    params = { 'preliminary' : 'true' }\n",
    "    data = jikan_get_request(endpoint, anime_id, params)\n",
    "    data_filtered = filter_reviews(data, top_k)\n",
    "    \n",
    "    reviews_formatter = \"REVIEWS: {}\\nSource: MyAnimeList.net\"\n",
    "    reviews_as_string = format_reviews(data_filtered)\n",
    "    data_parsed = reviews_formatter.format(reviews_as_string)\n",
    "    return data_parsed\n",
    "\n",
    "def get_anime_info(anime_id: int, option: str) -> str:\n",
    "    if (option == \"statistics\"):\n",
    "        return get_anime_statistics(anime_id)\n",
    "    elif (option == \"recommendations\"):\n",
    "        return get_anime_recommendations(anime_id)\n",
    "    elif (option == \"reviews\"):\n",
    "        return get_anime_reviews(anime_id)\n",
    "\n",
    "option = \"reviews\"\n",
    "print(get_anime_info(20, option))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeStatsInputSchema(BaseModel):\n",
    "    id: int = Field(description=\"anime id\")\n",
    "\n",
    "class AnimeStatsTool(BaseTool):\n",
    "    name = \"anime_stats\"\n",
    "    description = \"Useful for looking up the statistics on an anime, like the ratings people have given it\"\n",
    "    args_schema: Type[AnimeStatsInputSchema] = AnimeStatsInputSchema\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        id: int,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        try:    \n",
    "            anime_stats = get_anime_statistics(id)\n",
    "            return anime_stats\n",
    "        except Exception as e:\n",
    "            raise ToolException(e)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        id: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"anime_stats does not support async\")\n",
    "\n",
    "class AnimeRecommendationsInputSchema(BaseModel):\n",
    "    id: int = Field(description=\"anime id\")\n",
    "    num: int = Field(description=\"number of recommendations\")\n",
    "\n",
    "class AnimeRecommendationsTool(BaseTool):\n",
    "    name = \"anime_recommendations\"\n",
    "    description = \"Useful for looking up recommendations based on a given anime\"\n",
    "    args_schema: Type[AnimeRecommendationsInputSchema] = AnimeRecommendationsInputSchema\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        id: int,\n",
    "        num: int,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        try:    \n",
    "            anime_recommendations = get_anime_recommendations(id, num)\n",
    "            return anime_recommendations\n",
    "        except Exception as e:\n",
    "            raise ToolException(e)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        id: str,\n",
    "        num:int,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"anime_stats does not support async\")\n",
    "    \n",
    "class AnimeReviewsInputSchema(BaseModel):\n",
    "    id: int = Field(description=\"anime id\")\n",
    "\n",
    "class AnimeReviewsTool(BaseTool):\n",
    "    name = \"anime_reviews\"\n",
    "    description = \"Useful for finding reviews for an anime and get an idea of sentiment\"\n",
    "    args_schema: Type[AnimeReviewsInputSchema] = AnimeReviewsInputSchema\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        id: int,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        try:    \n",
    "            anime_reviews = get_anime_reviews(id)\n",
    "            return anime_reviews\n",
    "        except Exception as e:\n",
    "            raise ToolException(e)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        id: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"anime_stats does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `anime_id_lookup` with `{'query': 'Sousou no Frieren'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m52991\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `anime_stats` with `{'id': 52991}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mSCORES: 1/10, Votes for score: 2259, Percentage of total: 1.9\n",
      "2/10, Votes for score: 189, Percentage of total: 0.2\n",
      "3/10, Votes for score: 193, Percentage of total: 0.2\n",
      "4/10, Votes for score: 320, Percentage of total: 0.3\n",
      "5/10, Votes for score: 798, Percentage of total: 0.7\n",
      "6/10, Votes for score: 1460, Percentage of total: 1.2\n",
      "7/10, Votes for score: 4390, Percentage of total: 3.6\n",
      "8/10, Votes for score: 13920, Percentage of total: 11.5\n",
      "9/10, Votes for score: 30865, Percentage of total: 25.6\n",
      "10/10, Votes for score: 66274, Percentage of total: 54.9\n",
      "Source: MyAnimeList.net\u001b[0m\u001b[32;1m\u001b[1;3m\"Sousou no Frieren\" is an anime series that is based on a manga of the same name. It follows the story of Frieren, a 10,000-year-old witch who has been granted eternal youth and immortality. Frieren has lived through countless generations and has witnessed the rise and fall of civilizations.\n",
      "\n",
      "The anime explores Frieren's journey as she meets different characters and experiences various adventures. Along the way, she learns about the value of life, friendship, and the fleeting nature of time.\n",
      "\n",
      "Please note that the anime has received mixed reviews, with some viewers praising its unique concept and emotional storytelling, while others have criticized its pacing and character development.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0, openai_api_key=key)\n",
    "\n",
    "anime_id_lookup_tool = AnimeIDLookupTool()\n",
    "anime_id_lookup_tool.handle_tool_error = True\n",
    "\n",
    "anime_stats_tool = AnimeStatsTool()\n",
    "anime_stats_tool.handle_tool_error = True\n",
    "\n",
    "anime_recommendations_tool = AnimeRecommendationsTool()\n",
    "anime_recommendations_tool.handle_tool_error = True\n",
    "\n",
    "anime_reviews_tool = AnimeReviewsTool()\n",
    "anime_reviews_tool.handle_tool_error = True\n",
    "\n",
    "tools = [anime_id_lookup_tool, anime_stats_tool, anime_recommendations_tool, anime_reviews_tool]\n",
    "agent_kwargs = {\n",
    "    \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"memory\")],\n",
    "}\n",
    "memory = ConversationBufferMemory(memory_key=\"memory\", return_messages=True)\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True, agent_kwargs=agent_kwargs, memory=memory\n",
    ")\n",
    "\n",
    "result =agent_executor({\"input\": \"Do you think I should watch Jujutsu Kaisen?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OpenAPI has a major drawback in that it naturally causes the LLM to perform inference more than necessary due to the sheer number of endpoints available. As the LLM performs reasoning to respond to a user query, it calls any endpoint that may be helpful, despite the fact that often only one or two endpoints will return the necessary information. Considering that only a subset of the endpoints is necessary to achieve core functionality, this means the cost of inference is unnecessarily high. Thus, for AniMate, I will use the custom tools approach, and only implement tools for a subset of the endpoints. This will keep the number of tokens required for inference down and reduce the complexity of AniMate's implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `anime_id_lookup` with `{'query': 'Sousou no Frieren'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m52991\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `anime_stats` with `{'id': 52991}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mSCORES: 1/10, Votes for score: 2259, Percentage of total: 1.9\n",
      "2/10, Votes for score: 189, Percentage of total: 0.2\n",
      "3/10, Votes for score: 193, Percentage of total: 0.2\n",
      "4/10, Votes for score: 320, Percentage of total: 0.3\n",
      "5/10, Votes for score: 798, Percentage of total: 0.7\n",
      "6/10, Votes for score: 1460, Percentage of total: 1.2\n",
      "7/10, Votes for score: 4390, Percentage of total: 3.6\n",
      "8/10, Votes for score: 13920, Percentage of total: 11.5\n",
      "9/10, Votes for score: 30865, Percentage of total: 25.6\n",
      "10/10, Votes for score: 66274, Percentage of total: 54.9\n",
      "Source: MyAnimeList.net\u001b[0m\u001b[32;1m\u001b[1;3mBased on the statistics from MyAnimeList, Sousou no Frieren has a high average score of 9.0/10 with a significant number of votes. This suggests that the majority of viewers have enjoyed the anime and have given it positive ratings. Therefore, it seems like Sousou no Frieren is worth watching.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `anime_id_lookup` with `{'query': 'Sousou no Frieren'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m52991\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `anime_reviews` with `{'id': 52991}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mREVIEWS: Review Summary: Sousou no Frieren is a captivating and emotionally moving anime with superb animation and a profound exploration of themes such as friendship, love, loss, and the meaning of life.\n",
      "Review Summary: This review praises the series for its ability to captivate the sense of time and the grand lifespan of the main character, while also leaving the audience curious about her past journeys and experiences, ultimately recommending it as a must-watch with similarities to Violet Evergarden and Vivy: Fluorite Eyes Song.\n",
      "Review Summary: The reviewer finds the fantasy setting of the anime \"Frieren: Beyond Journey's End\" generic and uninteresting, with a lack of depth and complexity in its emotional journey story, making it underwhelming and mediocre overall.\n",
      "Review Summary: Frieren is a unique and masterful anime with excellent storytelling and worldbuilding, but it may not appeal to the average anime fan due to its lack of traditional fantasy tropes and emphasis on character development and symbolism.\n",
      "Review Summary: \"Sousou no Frieren is a thought-provoking series that encourages reflection on life's regrets and the importance of cherishing the present moment.\"\n",
      "Source: MyAnimeList.net\u001b[0m\u001b[32;1m\u001b[1;3mHere are some reviews of Sousou no Frieren:\n",
      "\n",
      "1. Review Summary: Sousou no Frieren is a captivating and emotionally moving anime with superb animation and a profound exploration of themes such as friendship, love, loss, and the meaning of life.\n",
      "\n",
      "2. Review Summary: This review praises the series for its ability to captivate the sense of time and the grand lifespan of the main character, while also leaving the audience curious about her past journeys and experiences, ultimately recommending it as a must-watch with similarities to Violet Evergarden and Vivy: Fluorite Eyes Song.\n",
      "\n",
      "3. Review Summary: The reviewer finds the fantasy setting of the anime \"Frieren: Beyond Journey's End\" generic and uninteresting, with a lack of depth and complexity in its emotional journey story, making it underwhelming and mediocre overall.\n",
      "\n",
      "4. Review Summary: Frieren is a unique and masterful anime with excellent storytelling and worldbuilding, but it may not appeal to the average anime fan due to its lack of traditional fantasy tropes and emphasis on character development and symbolism.\n",
      "\n",
      "5. Review Summary: \"Sousou no Frieren is a thought-provoking series that encourages reflection on life's regrets and the importance of cherishing the present moment.\"\n",
      "\n",
      "These reviews provide a range of perspectives on Sousou no Frieren, but overall, it seems to be well-received by viewers.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia_lookup` with `{'query': 'Sousou no Frieren'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Frieren\n",
      "Summary: Frieren: Beyond Journey's End (Japanese: 葬送のフリーレン, Hepburn: Sōsō no Furīren, pp. \"Frieren, the Final Farewell to the Dead\") is a Japanese manga series written by Kanehito Yamada and illustrated by Tsukasa Abe. It has been serialized in Shogakukan's shōnen manga magazine Weekly Shōnen Sunday since April 2020, with its chapters collected in twelve tankōbon volumes as of December 2023. The series is licensed for English release in North America by Viz Media. An anime television series adaptation produced by Madhouse premiered in September 2023.\n",
      "By December 2023, the manga had over 17 million copies in circulation. In 2021, Frieren: Beyond Journey's End won the 14th Manga Taishō and the New Creator Prize of the 25th annual Tezuka Osamu Cultural Prize.\n",
      "\n",
      "Page: Frieren (character)\n",
      "Summary: Frieren (Japanese: フリーレン, Hepburn: Furīren) is the title character and protagonist of the Japanese manga series Frieren: Beyond Journey's End, written by Kanehito Yamada and illustrated by Tsukasa Abe. Frieren is a former member of the party of adventurers who defeated the Demon King and restored harmony to the world after a ten-year quest. Frieren returns to the capital fifty years later; however, humanity has changed, and her former companions have distinctly aged. After one last adventure to see the meteor shower, Himmel dies of old age. During the funeral, Frieren expressed guilt for not attempting to learn more about him. Frieren then pays a visit to her other former comrades. She accepts an offer to teach and care for Fern, an orphaned child adopted by Heiter. She also receives an invitation to travel far north, to the resting place of souls, and see Himmel again to bid the hero a fitting farewell and express her feelings. To fulfill those requests, Frieren embarks on a journey together with Fern while still pursuing her passion for learning magic.\n",
      "While initially conceptualized as a comical fighter, Yamada scrapped multiple ideas she had for Frieren until deciding to make her an elf who grows in the story while remembering Himmel. In the anime adaptation, she is voiced by Atsumi Tanezaki in Japanese and Mallorie Rodak in English. Critical response to Frieren's character was mostly positive due to how the series focuses on Frieren's view of life and how she aims to become a better person. The further exploration of her dark past was also praised for how it changed people's views of her.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mSousou no Frieren, also known as Frieren: Beyond Journey's End, is a Japanese manga series written by Kanehito Yamada and illustrated by Tsukasa Abe. It has been serialized in Shogakukan's shōnen manga magazine Weekly Shōnen Sunday since April 2020. The story follows the title character, Frieren, who is a former member of a party of adventurers that defeated the Demon King and brought peace to the world. However, when Frieren returns to the capital fifty years later, she finds that her former companions have aged and humanity has changed. Frieren embarks on a journey to fulfill requests and bid farewell to her fallen comrades, all while teaching and caring for an orphaned child named Fern. The series explores themes of friendship, love, loss, and the meaning of life.\n",
      "\n",
      "The manga has received critical acclaim and has won awards such as the 14th Manga Taishō and the New Creator Prize of the 25th annual Tezuka Osamu Cultural Prize. An anime television series adaptation produced by Madhouse premiered in September 2023.\n",
      "\n",
      "Please note that the information provided is a summary of the series and may not cover all aspects of the story.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0, openai_api_key=key)\n",
    "\n",
    "anime_id_lookup_tool = AnimeIDLookupTool()\n",
    "anime_id_lookup_tool.handle_tool_error = True\n",
    "\n",
    "anime_stats_tool = AnimeStatsTool()\n",
    "anime_stats_tool.handle_tool_error = True\n",
    "\n",
    "anime_recommendations_tool = AnimeRecommendationsTool()\n",
    "anime_recommendations_tool.handle_tool_error = True\n",
    "\n",
    "anime_reviews_tool = AnimeReviewsTool()\n",
    "anime_reviews_tool.handle_tool_error = True\n",
    "\n",
    "tools = [wiki_tool, anime_id_lookup_tool, anime_stats_tool, anime_recommendations_tool, anime_reviews_tool]\n",
    "agent_kwargs = {\n",
    "    \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"memory\")],\n",
    "}\n",
    "memory = ConversationBufferMemory(memory_key=\"memory\", return_messages=True)\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True, agent_kwargs=agent_kwargs, memory=memory\n",
    ")\n",
    "\n",
    "result = agent_executor({\"input\": \"Do you think I should watch Sousou no Frieren?\"})\n",
    "result = agent_executor({\"input\": \"Ok, what are people saying about Sousou no Frieren?\"})\n",
    "result = agent_executor({\"input\": \"Interesting, what's it about?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
